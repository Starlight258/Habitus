# Choosing the Right Algorithm for Activity Recommendations

## The Beginning: A Seemingly Simple Problem

I was tasked with building an activity recommendation feature for the Habitus project. The requirement was clear: "
Recommend the optimal combination of activities to users within their available time based on their personal
priorities." At first, I thought it'd be simpleâ€”just pick the most efficient activities first, right?

But when I actually started implementing it, things got more complicated than expected.

## First Attempt: Greedy

The first approach that came to mind was Greedy. Select activities with the highest efficiency (score/time) first. It's
simple to implement and runs in O(n log n). Sounds perfect.

I tested it with a simple example: 4 activities, 100 minutes available.

- A: 10min, 11pts (efficiency: 1.1) ğŸ‘‘
- B: 50min, 50pts (efficiency: 1.0)
- C: 50min, 50pts (efficiency: 1.0)
- D: 95min, 99pts (efficiency: 1.04)

Sorted by efficiency: A â†’ D â†’ B â†’ C

1. Select A (10min, 11pts) â†’ 90min remaining
2. Try D â†’ needs 95min âŒ
3. Select B (50min, 50pts) â†’ 40min remaining
4. Try C â†’ needs 50min âŒ

**Result: A + B = 60min, 61pts**

But when I calculated by hand, **B + C = 100min, 100pts**. Greedy failed.

By selecting A (efficiency 1.1), I couldn't fit D and also missed C. I got caught up in a small efficiency difference
and missed the bigger picture. Greedy only sees "the best right now" and can't guarantee the global optimum.

## Second Thought: Brute Force

What if I try all combinations? With 4 activities, that's 2^4 = 16 cases.

1. {} â†’ 0pts
2. {A} â†’ 11pts
   ...
8. {B,C} â†’ 100pts âœ…
9. {A,B,C} â†’ 110min (exceeds limit) âŒ

It guarantees the correct answer, but with O(2^n), it takes over a second once you hit 25 activities. Not scalable.

## Final Choice: Dynamic Programming

This is a classic 0-1 Knapsack problem. With DP, we can guarantee the optimal solution in O(n Ã— W).

### Core Idea of DP

```
dp[i][w] = maximum value when considering i activities with w minutes used

dp[i][w] = max(
    dp[i-1][w],                      // don't select
    dp[i-1][w-time[i]] + value[i]    // select
)
```

Building the table:

```
         w=0   w=10  w=50  w=60  w=95  w=100
    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
  0 â”‚  0 â”‚  0  â”‚  0  â”‚  0  â”‚  0  â”‚  0  â”‚   0  â”‚
  A â”‚  0 â”‚ 11  â”‚ 11  â”‚ 11  â”‚ 11  â”‚ 11  â”‚  11  â”‚
  B â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 61  â”‚ 61  â”‚  61  â”‚
  C â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 61  â”‚ 61  â”‚ 100  â”‚
  D â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 99  â”‚ 99  â”‚ 100  â”‚
    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

dp[4][100] = 100 is our maximum value.

### Backtracking to Find Selected Activities

If the value changed, that activity was selected.

```
dp[4][100] = 100, dp[3][100] = 100 â†’ D not selected
dp[3][100] = 100, dp[2][100] = 61  â†’ C selected! (50min left)
dp[2][50] = 50, dp[1][50] = 11     â†’ B selected! (0min left)
```

**Selected: B, C â†’ 100min, 100pts âœ…**

## Implementation

```java
private int[][] buildDpTable(List<SelectedActivity> activities, int maxMinutes) {
    int n = activities.size();
    int[][] dp = new int[n + 1][maxMinutes + 1];

    for (int i = 1; i <= n; i++) {
        SelectedActivity cur = activities.get(i - 1);
        int duration = cur.getActivity().getDurationMinutes();
        int value = cur.getValue();

        for (int w = 0; w <= maxMinutes; w++) {
            dp[i][w] = dp[i - 1][w];
            if (w >= duration) {
                dp[i][w] = Math.max(dp[i][w], dp[i - 1][w - duration] + value);
            }
        }
    }
    return dp;
}
```

Backtracking:

```java
private List<SelectedActivity> backtrack(
        List<SelectedActivity> activities, int[][] dp, int maxMinutes
) {
    List<SelectedActivity> selected = new ArrayList<>();
    int n = activities.size();
    int w = maxMinutes;

    for (int i = n; i > 0 && w > 0; i--) {
        if (dp[i][w] != dp[i - 1][w]) {
            selected.add(activities.get(i - 1));
            w -= activities.get(i - 1).getActivity().getDurationMinutes();
        }
    }

    Collections.reverse(selected);
    return selected;
}
```

## Performance Comparison

<img width="1724" height="906" alt="image" src="https://github.com/user-attachments/assets/1c383b59-745a-4395-81f0-cbcaa599a96d" />

<img width="1572" height="962" alt="image" src="https://github.com/user-attachments/assets/8de11645-c2cb-44e8-9695-b0d4f36c7d7b" />

Current project scale: 5 activities, 10,080 minutes (1 week)

- DP: 5 Ã— 10,080 = 50,400 operations (0.017ms)
- Brute Force: 2^5 = 32 operations

If scaled to 20 activities:

- DP: 20 Ã— 10,080 = 201,600 operations (under 1ms)
- Brute Force: 2^20 = 1,048,576 operations (1 second)

| Algorithm   | Time Complexity | Optimal | Notes                  |
|-------------|-----------------|---------|------------------------|
| Greedy      | O(n log n)      | âŒ       | Fast but inaccurate    |
| Brute Force | O(2^n)          | âœ…       | Accurate but slow      |
| DP          | O(n Ã— W)        | âœ…       | Accurate and efficient |

## Future Improvements

**Recalculation Issue**: The entire DP table recalculates whenever users modify activities. This could be improved with
caching or incremental computation.

**Scaling Up**: For 100+ activities, an approximation algorithm (Greedy + post-processing) could be considered. It
achieves 90-98% accuracy while being 60x faster.

## Conclusion

I initially thought "just pick the most efficient ones first," but Greedy couldn't guarantee the optimal solution. DP
provided both accuracy and efficiency. I learned that choosing an algorithm isn't about "which is fastest" but "which
fits the problem characteristics and input size."

# Korean version - í™œë™ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜, ì„ íƒ ê¸°ì¤€

## ê°œìš”

Habitus í”„ë¡œì íŠ¸ì—ì„œ í™œë™ ì¶”ì²œ ê¸°ëŠ¥ì„ ë§Œë“¤ê²Œ ëë‹¤.
"ì‚¬ìš©ìì—ê²Œ ì œí•œëœ ì‹œê°„ ì•ˆì—ì„œ ê°œì¸ ìš°ì„ ìˆœìœ„ì— ë§ëŠ” ìµœì ì˜ í™œë™ ì¡°í•©ì„ ì¶”ì²œí•˜ì."
ì²˜ìŒì—” íš¨ìœ¨ ì¢‹ì€ ê²ƒë¶€í„° ë„£ìœ¼ë©´ ë˜ì§€ ì•Šì„ê¹Œ ì‹¶ì—ˆë‹¤. í•˜ì§€ë§Œ ë§‰ìƒ êµ¬í˜„í•˜ë ¤ë‹ˆ ìƒê°ë³´ë‹¤ ë³µì¡í–ˆë‹¤.

## ì²« ë²ˆì§¸ ì‹œë„: Greedy

ê°€ì¥ ë¨¼ì € ë– ì˜¤ë¥¸ ê±´ Greedyì˜€ë‹¤. íš¨ìœ¨(ì ìˆ˜/ì‹œê°„)ì´ ë†’ì€ ê²ƒë¶€í„° ì„ íƒí•˜ëŠ” ë°©ì‹ì´ë‹¤. êµ¬í˜„ë„ ê°„ë‹¨í•˜ê³  O(n log n)ìœ¼ë¡œ ë¹ ë¥´ë‹¤.

ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ í…ŒìŠ¤íŠ¸í–ˆë‹¤.

í™œë™ 4ê°œ, ì‹œê°„ 100ë¶„

- A: 10ë¶„, 11ì  (íš¨ìœ¨ 1.1) ğŸ‘‘
- B: 50ë¶„, 50ì  (íš¨ìœ¨ 1.0)
- C: 50ë¶„, 50ì  (íš¨ìœ¨ 1.0)
- D: 95ë¶„, 99ì  (íš¨ìœ¨ 1.04)

íš¨ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ë©´ A â†’ D â†’ B â†’ Cë‹¤.

1. A ì„ íƒ (10ë¶„, 11ì ) â†’ ë‚¨ì€ 90ë¶„
2. D ì‹œë„ â†’ 95ë¶„ í•„ìš” âŒ
3. B ì„ íƒ (50ë¶„, 50ì ) â†’ ë‚¨ì€ 40ë¶„
4. C ì‹œë„ â†’ 50ë¶„ í•„ìš” âŒ

**ê²°ê³¼: A + B = 60ë¶„, 61ì **

ê·¸ëŸ°ë° ì†ìœ¼ë¡œ ìµœì í™”ëœ ì¡°í•©ì„ ê³„ì‚°í•˜ë‹ˆ **B + C = 100ë¶„, 100ì **ì´ ë‚˜ì™”ë‹¤. Greedyê°€ í‹€ë ¸ë‹¤ !

Aì˜ íš¨ìœ¨(1.1)ì´ ê°€ì¥ ë†’ì•„ì„œ ì„ íƒí–ˆëŠ”ë°, ê·¸ ë•Œë¬¸ì— Dë¥¼ ëª» ë„£ê³  Cë„ ë†“ì³¤ë‹¤.
ì‘ì€ íš¨ìœ¨ ì°¨ì´ì— ì§‘ì°©í•˜ë‹¤ê°€ í° ê·¸ë¦¼ì„ ë†“ì¹œ ê±°ë‹¤. GreedyëŠ” "ì§€ê¸ˆ ë‹¹ì¥ ìµœì„ "ë§Œ ë³´ê¸° ë•Œë¬¸ì— ì „ì²´ ìµœì ì„ ë³´ì¥í•˜ì§€ ëª»í•œë‹¤. (ê·¼ì‹œì•ˆì ì¸ í•´ë¥¼ ì œê³µí•œë‹¤)

## ë‘ ë²ˆì§¸ ê³ ë¯¼: Brute Force

ëª¨ë“  ê²½ìš°ë¥¼ ë‹¤ í•´ë³´ë©´? 4ê°œ í™œë™ì´ë©´ 2^4 = 16ê°€ì§€ë‹¤.

1. {} â†’ 0ì 
2. {A} â†’ 11ì 
3. ...
4. {B,C} â†’ 100ì  âœ…
5. {A,B,C} â†’ 110ë¶„ ì´ˆê³¼ âŒ

ë¬´ì¡°ê±´ ì •ë‹µì„ ì°¾ì§€ë§Œ, O(2^n)ì´ë¼ í™œë™ 25ê°œë¶€í„° 1ì´ˆë¥¼ ë„˜ê¸´ë‹¤. í™•ì¥ì„±ì´ ì—†ë‹¤.

## ìµœì¢… ì„ íƒ: Dynamic Programming

ì´ ë¬¸ì œëŠ” ì „í˜•ì ì¸ **0-1 Knapsack**ì´ë‹¤. DPë¡œ ì ‘ê·¼í•˜ë©´ **O(n Ã— W)**ë¡œ ìµœì í•´ë¥¼ ë³´ì¥ë°›ëŠ”ë‹¤.

### DPì˜ í•µì‹¬

`dp[i][w]` = iê°œ í™œë™ì„ ë³´ê³ , wë¶„ ì‚¬ìš©í–ˆì„ ë•Œ ìµœëŒ€ ê°€ì¹˜

```
dp[i][w] = max(
    dp[i-1][w],                      // ì„ íƒ ì•ˆí•¨
    dp[i-1][w-time[i]] + value[i]    // ì„ íƒí•¨
)
```

í…Œì´ë¸”ì„ ì±„ìš°ë©´:

```
         w=0   w=10  w=50  w=60  w=95  w=100
    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
  0 â”‚  0 â”‚  0  â”‚  0  â”‚  0  â”‚  0  â”‚  0  â”‚   0  â”‚
  A â”‚  0 â”‚ 11  â”‚ 11  â”‚ 11  â”‚ 11  â”‚ 11  â”‚  11  â”‚
  B â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 61  â”‚ 61  â”‚  61  â”‚
  C â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 61  â”‚ 61  â”‚ 100  â”‚
  D â”‚  0 â”‚ 11  â”‚ 50  â”‚ 61  â”‚ 99  â”‚ 99  â”‚ 100  â”‚
    â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

`dp[4][100] = 100`ì´ ìµœëŒ€ ê°€ì¹˜ë‹¤.

### ì—­ì¶”ì (backtracking)ìœ¼ë¡œ í™œë™ ì°¾ê¸°

ê°’ì´ ë‹¤ë¥´ë©´ í•´ë‹¹ í™œë™ì„ ì„ íƒí•œ ê²ƒì´ë‹¤.

1. `dp[4][100] = 100, dp[3][100] = 100` â†’ D ì„ íƒ ì•ˆí•¨
2. `dp[3][100] = 100, dp[2][100] = 61` â†’ C ì„ íƒ! (ë‚¨ì€ 50ë¶„)
3. `dp[2][50] = 50, dp[1][50] = 11` â†’ B ì„ íƒ! (ë‚¨ì€ 0ë¶„)

**ì„ íƒ: B, C â†’ 100ë¶„, 100ì  âœ…**

## ì‹¤ì œ êµ¬í˜„

```java
private int[][] buildDpTable(List<SelectedActivity> activities, int maxMinutes) {
    int n = activities.size();
    int[][] dp = new int[n + 1][maxMinutes + 1];

    for (int i = 1; i <= n; i++) {
        SelectedActivity cur = activities.get(i - 1);
        int duration = cur.getActivity().getDurationMinutes();
        int value = cur.getValue();

        for (int w = 0; w <= maxMinutes; w++) {
            dp[i][w] = dp[i - 1][w];
            if (w >= duration) {
                dp[i][w] = Math.max(dp[i][w], dp[i - 1][w - duration] + value);
            }
        }
    }
    return dp;
}
```

ì—­ì¶”ì :

```java
private List<SelectedActivity> backtrack(
        List<SelectedActivity> activities, int[][] dp, int maxMinutes
) {
    List<SelectedActivity> selected = new ArrayList<>();
    int n = activities.size();
    int w = maxMinutes;

    for (int i = n; i > 0 && w > 0; i--) {
        if (dp[i][w] != dp[i - 1][w]) {
            selected.add(activities.get(i - 1));
            w -= activities.get(i - 1).getActivity().getDurationMinutes();
        }
    }

    Collections.reverse(selected);
    return selected;
}
```

## ì„±ëŠ¥ ë¹„êµ

<img width="1724" height="906" alt="image" src="https://github.com/user-attachments/assets/1c383b59-745a-4395-81f0-cbcaa599a96d" />

<img width="1572" height="962" alt="image" src="https://github.com/user-attachments/assets/8de11645-c2cb-44e8-9695-b0d4f36c7d7b" />

í˜„ì¬ í”„ë¡œì íŠ¸: í™œë™ 5ê°œ, ì‹œê°„ 10,080ë¶„(1ì£¼ì¼)

- **DP**: 5 Ã— 10,080 = 50,400ë²ˆ ì—°ì‚° (0.017ms)
- **Brute Force**: 2^5 = 32ë²ˆ ì—°ì‚°

í™œë™ 20ê°œë¡œ ëŠ˜ì–´ë‚˜ë©´?

- **DP**: 20 Ã— 10,080 = 201,600ë²ˆ (1ms ì´í•˜)
- **Brute Force**: 2^20 = 1,048,576ë²ˆ (1ì´ˆ)

| ì•Œê³ ë¦¬ì¦˜        | ì‹œê°„ ë³µì¡ë„     | ìµœì í•´ | íŠ¹ì§•       |
|-------------|------------|-----|----------|
| Greedy      | O(n log n) | âŒ   | ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™• |
| Brute Force | O(2^n)     | âœ…   | ì •í™•í•˜ì§€ë§Œ ëŠë¦¼ |
| DP          | O(n Ã— W)   | âœ…   | ì •í™•í•˜ê³  íš¨ìœ¨ì  |

## í–¥í›„ ê°œì„  ë°©í–¥

**ë§¤ë²ˆ ì¬ê³„ì‚° ë¬¸ì œ**: ì‚¬ìš©ìê°€ í™œë™ì„ ìˆ˜ì •í•  ë•Œë§ˆë‹¤ ì „ì²´ ì¬ê³„ì‚°í•œë‹¤. ìºì‹±ì´ë‚˜ ì¦ë¶„ ê³„ì‚°ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥í•˜ë‹¤.

**ê·œëª¨ í™•ì¥ ì‹œ**: í™œë™ 100ê°œ ì´ìƒì´ë©´ ê·¼ì‚¬ ì•Œê³ ë¦¬ì¦˜(Greedy + í›„ì²˜ë¦¬)ì„ ê³ ë ¤í•  ìˆ˜ ìˆë‹¤. 90~98% ì •í™•ë„ë¡œ 60ë°° ë¹ ë¥´ë‹¤.

## ë§ˆë¬´ë¦¬í•˜ë©°

ì²˜ìŒì—” "íš¨ìœ¨ ë†’ì€ ê²ƒë¶€í„° ë„£ìœ¼ë©´ ë˜ì§€ ì•Šë‚˜?"ë¼ê³  ìƒê°í–ˆì§€ë§Œ, GreedyëŠ” ìµœì í•´ë¥¼ ë³´ì¥í•˜ì§€ ëª»í–ˆë‹¤.
DPëŠ” ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ëª¨ë‘ ë³´ì¥í•œë‹¤. ì•Œê³ ë¦¬ì¦˜ ì„ íƒì€ ì‹œê°„ ë³µì¡ë„, ê³µê°„ ë³µì¡ë„ë„ ì¤‘ìš”í•˜ì§€ë§Œ ë¬¸ì œ íŠ¹ì„±ì— ë§ê²Œ ì ì ˆí•œ ì •ë„ì˜ ì˜¬ë°”ë¥¸ í•´ë¥¼ ë³´ì¥í•˜ëŠ”ê°€ê°€ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤.
